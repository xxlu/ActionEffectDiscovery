{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mpl_toolkits\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('example.csv', ';',encoding='latin1')\n",
    "# data = pd.read_csv('~/Dropbox/workspace-python/LZDataPrepAndML/outV5.csv', '\\t',encoding='latin1')\n",
    "# data.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Effects  Responses  steps   c1   c2   c3   c4   c5   c6   c7   c8   c9  \\\n",
      "0        4          3    0.2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
      "1        4          3    0.2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
      "2        4          3    0.2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
      "3        4          3    0.2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
      "4        4          3    0.2  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
      "\n",
      "   c10  c11  c12  \n",
      "0  0.0  0.0  1.0  \n",
      "1  0.0  0.2  0.8  \n",
      "2  0.0  0.4  0.6  \n",
      "3  0.0  0.6  0.4  \n",
      "4  0.0  0.8  0.2  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    175616.0\n",
       "mean          3.0\n",
       "std           0.0\n",
       "min           3.0\n",
       "25%           3.0\n",
       "50%           3.0\n",
       "75%           3.0\n",
       "max           3.0\n",
       "Name: Responses, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EID  CID                Time Event                  Response\n",
      "0    1    1   12-05-2017 09:53     va                   Warning\n",
      "1    2    1   13-05-2017 13:35     po  DistractClient;Seclusion\n",
      "2    3    1   26-05-2017 09:32     va                   Warning\n",
      "3    4    1   26-05-2017 11:02     pp            DistractClient\n",
      "4    5    2   21-06-2017 14:51     va            DistractClient\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                      10\n",
       "unique                     10\n",
       "top       2017-06-24 17:02:00\n",
       "freq                        1\n",
       "first     2017-05-13 13:35:00\n",
       "last      2017-12-05 09:53:00\n",
       "Name: Time, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnTime = \"Time\"\n",
    "columnAction = \"Event\"\n",
    "columnResponse = \"Response\"\n",
    "columnCaseid = \"CID\"\n",
    "columnEventid = \"EID\"\n",
    "\n",
    "# columnTime = \"Algemeen: Datum incident\"\n",
    "# columnAction = \"Aggression_short\"\n",
    "# columnResponse = \"[B09] Maatregelen om agressie te stoppen\"\n",
    "# columnCaseid = \"Pseudoniem_client\"\n",
    "# columnEventid = \"Meldingsnummer\"\n",
    "\n",
    "\n",
    "\n",
    "columnEffect = \"Next_Type_Eps\"\n",
    "data[columnTime].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data[columnTime] = pd.to_datetime(data[columnTime])\n",
    "# data = data.sort_values('Algemeen: Datum incident') # This now sorts in date \n",
    "\n",
    "##\n",
    "## Sorting the incident. Only then the shift works well. \n",
    "##\n",
    "data.sort_values([columnCaseid, columnTime, columnEventid], ascending=[True, True, True], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Shift the data that is grouped by the clients to calculate the next incident type and next incident date\n",
    "#\n",
    "data['Next_Type'] = data.groupby(columnCaseid)[columnAction].shift(-1)\n",
    "data['Next_DayOfIncident'] = data.groupby(columnCaseid)[columnTime].shift(-1)\n",
    "\n",
    "#\n",
    "# Set the data type of the next date \n",
    "#\n",
    "data['Next_DayOfIncident'] = pd.to_datetime(data['Next_DayOfIncident'])\n",
    "\n",
    "#\n",
    "# Calculate the difference. \n",
    "#\n",
    "data[\"Next_DaysToNext\"] = (data['Next_DayOfIncident'] - data[columnTime])/np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 1 : preprocess log using epsilon\n",
    "eps = 7\n",
    "\n",
    "data.loc[data['Next_DaysToNext'] <= eps, columnEffect] = data['Next_Type']\n",
    "data.loc[data['Next_DaysToNext'] > eps, columnEffect] = 'Tau' \n",
    "\n",
    "# data.fillna(\"NaN\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       7\n",
       "unique      4\n",
       "top       Tau\n",
       "freq        3\n",
       "Name: Next_Type_Eps, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data[columnEffect].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['po', 'va', 'pp']\n",
      "{'DistractClient', 'Warning', 'NoResponse', 'Seclusion'}\n"
     ]
    }
   ],
   "source": [
    "cNextT = columnAction\n",
    "cCurrT = columnEffect\n",
    "\n",
    "setActions = pd.Series(data[columnAction]).drop_duplicates().tolist()\n",
    "print(setActions)\n",
    "\n",
    "columnname = columnResponse\n",
    "cMeasureValues = pd.Series(data[columnResponse]).drop_duplicates().tolist()\n",
    "# print(cMeasureValues)\n",
    "\n",
    "\n",
    "setResponse = set()\n",
    "for i in cMeasureValues:\n",
    "    for v in str(i).split(';'):\n",
    "        setResponse.add(v.strip())\n",
    "\n",
    "print(setResponse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'columnTot': {'pp': 1, 'Tau': 1, 'NaN': 2, 'va': 1, 'po': 1}, 'Warning': {'pp': 1, 'NaN': 1, 'po': 1}, 'DistractClient': {'Tau': 1, 'va': 1}, 'NoResponse': {'NaN': 1}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data['Next_Type_Eps'].replace(np.nan, \"NaN\", inplace = True)\n",
    "\n",
    "\n",
    "# FF = calcFreqMeasuresCombined2DDict(data, columnname+cMeasureValues[0])\n",
    "FF = calcFreqMeasures2DDict(data, columnAction, columnResponse, columnEffect, setResponse)\n",
    "# F = calcFreq2DDict(data, cMeasureT)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label = \"va\"\n",
    "F = FF[label]\n",
    "print(F)\n",
    "\n",
    "# for ai in F:\n",
    "#     F[ai][ai] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                NaN  Tau   po   pp   va\n",
      "columnTot       2.0  1.0  1.0  1.0  1.0\n",
      "Warning         1.0  NaN  1.0  1.0  NaN\n",
      "DistractClient  NaN  1.0  NaN  NaN  1.0\n",
      "NoResponse      1.0  NaN  NaN  NaN  NaN\n",
      "                Tau   po   pp   va\n",
      "Warning         0.0  1.0  1.0  0.0\n",
      "DistractClient  1.0  0.0  0.0  1.0\n",
      "NoResponse      0.0  0.0  0.0  0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The internally computed table of expected frequencies has a zero element at (2, 0).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-26b62f40e2a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchi2_cont_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-812f032ae078>\u001b[0m in \u001b[0;36mchi2_cont_row\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchi2_cont_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchi2_contingency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dof=%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/stats/contingency.py\u001b[0m in \u001b[0;36mchi2_contingency\u001b[0;34m(observed, correction, lambda_)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mzeropos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         raise ValueError(\"The internally computed table of expected \"\n\u001b[0;32m--> 254\u001b[0;31m                          \"frequencies has a zero element at %s.\" % (zeropos,))\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;31m# The degrees of freedom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The internally computed table of expected frequencies has a zero element at (2, 0)."
     ]
    }
   ],
   "source": [
    "# -----------------\n",
    "# Example : two dimentional dictionary to data frame\n",
    "# ------------------\n",
    "# tableRe = pd.DataFrame(Frelative).T\n",
    "\n",
    "# print(tableRe)\n",
    "# chi2_cont_row(tableRe)\n",
    "\n",
    "table = pd.DataFrame(F).T\n",
    "print(table)\n",
    "table.fillna(0, inplace=True)\n",
    "table.drop(columns=['NaN'], inplace = True)\n",
    "table.drop(index=['columnTot'], inplace = True)\n",
    "table.dropna\n",
    "print(table)\n",
    "stat, p, dof, expected = chi2_cont_row(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'columnTot': {'pp': 1, 'Tau': 1, 'NaN': 2, 'va': 1, 'po': 1}, 'Warning': {'pp': 1, 'NaN': 1, 'po': 1}, 'DistractClient': {'Tau': 1, 'va': 1}, 'NoResponse': {'NaN': 1}}\n",
      "                Tau   po   pp   va\n",
      "columnTot       1.0  1.0  1.0  1.0\n",
      "Warning         0.0  1.0  1.0  0.0\n",
      "DistractClient  1.0  0.0  0.0  1.0\n",
      "NoResponse      0.0  0.0  0.0  0.0\n",
      "=======\n",
      "Warning\n",
      "Warning\n",
      "skip\n",
      "=======\n",
      "DistractClient\n",
      "DistractClient\n",
      "skip\n",
      "=======\n",
      "NoResponse\n",
      "NoResponse\n",
      "skip\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-eeacef306ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mp_adjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultipletests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bonferroni'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;31m# Print the resulting conclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_adjusted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/statsmodels/stats/multitest.py\u001b[0m in \u001b[0;36mmultipletests\u001b[0;34m(pvals, alpha, method, is_sorted, returnsorted)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mntests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0malphacSidak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malphaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mntests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0malphacBonf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphaf\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bonf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bonferroni'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "import pygraphviz as pgv\n",
    "\n",
    "# chi-squared test with similar proportions\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import statsmodels.api as sm       \n",
    "\n",
    "from itertools import combinations \n",
    "\n",
    "pos = \"all\"\n",
    "\n",
    "label = 'va'\n",
    "start = label\n",
    "name = label\n",
    "F = FF[label]\n",
    "print(F)\n",
    "\n",
    "table = pd.DataFrame(F).T\n",
    "table.replace(np.nan,0, inplace = True)\n",
    "table.drop(columns=['NaN'], inplace = True)\n",
    "print(table)\n",
    "\n",
    "G = pgv.AGraph(strict=False, directed=True, landscape=True)\n",
    "G.graph_attr['rankdir'] ='LR'\n",
    "G.node_attr['shape']= 'box'\n",
    "G.clear()\n",
    "    \n",
    "\n",
    "pvalues = list() # keep a list of computed p values to use for adjusting p-values\n",
    "\n",
    "adjresidual = 2.57\n",
    "for ai in F:\n",
    "    if(ai == 'columnTot'):\n",
    "        continue\n",
    "    print(\"=======\")\n",
    "    print(ai)\n",
    "    newF = dict()\n",
    "    newF['non'] = dict()\n",
    "    newF[ai] = dict()\n",
    "    bool_observed_zero = False\n",
    "    for aj in table.columns:\n",
    "        # expected cell >= 5\n",
    "        # observed count cell >= 1\n",
    "        # observed count 75% cells  >= 5\n",
    "\n",
    "        if(aj not in F[ai] or F[ai][aj] == 0 or pd.isnull(F[ai][aj])):\n",
    "            bool_observed_zero = True\n",
    "            print(ai)\n",
    "            break\n",
    "    \n",
    "        newF[ai][aj] = F[ai][aj]\n",
    "        newF['non'][aj] = table.at['columnTot',aj] - F[ai][aj]\n",
    "    if bool_observed_zero:\n",
    "        print(\"skip\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    newTable = pd.DataFrame(newF).T\n",
    "    stat, p, dof, expected = chi2_cont_row(newTable)\n",
    "    \n",
    "    expectedT = pd.DataFrame(expected, columns = newTable.columns, index = newTable.index)\n",
    "\n",
    "    \n",
    "    if (p <= 0.05):\n",
    "        rtable = sm.stats.Table(newTable)     \n",
    "#         print(rtable.resid_pearson)\n",
    "#         print(rtable.standardized_resids)\n",
    "        \n",
    "        subtable = pd.DataFrame(rtable.standardized_resids)\n",
    "#         print(subtable)\n",
    "#         print(newTable)\n",
    "#         print(expectedT)\n",
    "        \n",
    "        for aj in table.columns:\n",
    "            if (subtable.at[ai,aj] < -adjresidual) or (subtable.at[ai,aj] > adjresidual):\n",
    "                if(G.has_edge(start+\"_s\", ai) == False):\n",
    "                    rowtot = newTable.sum(axis=1)[ai]\n",
    "                    G.add_edge(start+\"_s\", ai, label=\"{0:.0f}\".format(rowtot))\n",
    "                if(subtable.at[ai,aj] > 2.57):\n",
    "                    penwidthl='3' # TODO replace with a function \n",
    "                else:\n",
    "                    penwidthl='1'\n",
    "                G.add_edge(ai, aj, penwidth=penwidthl, label=\"{0:.0f}\".format(newTable.at[ai,aj]) + \"(\"+ \"{0:.0f}\".format(expectedT.at[ai,aj]) +\")\")\n",
    "    pvalues.append(p)\n",
    "    \n",
    "G.draw('./graph_' + name + '-asr' + pos + '.png', prog='dot')\n",
    "    \n",
    "    \n",
    "p_adjusted = multipletests(pvalues, alpha=.05, method='bonferroni')\n",
    "# Print the resulting conclusions\n",
    "print(p_adjusted[0])\n",
    "\n",
    "# Print the adjusted p-values themselves \n",
    "print(p_adjusted[1])\n",
    "print(\"////////////\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chi2_cont_row(df):\n",
    "    stat, p, dof, expected = chi2_contingency(df, correction=True)\n",
    "    print('dof=%d' % dof)\n",
    "    print(expected)\n",
    "\n",
    "    # interpret test-statistic\n",
    "    prob = 0.95\n",
    "    critical = chi2.ppf(prob, dof)\n",
    "    print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "\n",
    "    if abs(stat) >= critical:\n",
    "        print('Dependent (reject H0)')\n",
    "    else:\n",
    "        print('Independent (fail to reject H0)')\n",
    "\n",
    "\n",
    "    # interpret p-value\n",
    "    alpha = 1.0 - prob\n",
    "    print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "    if p <= alpha:\n",
    "        print('Dependent (reject H0)')\n",
    "    else:\n",
    "        print('Independent (fail to reject H0)')\n",
    "    return stat, p, dof, expected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFreqMeasures2DDict(data, cCurrT, columnResponse, cNextT, setResponses):\n",
    "    F = dict()\n",
    "    for index, row in data.iterrows():\n",
    "        currT = row[cCurrT]\n",
    "        nextT = row[cNextT]\n",
    "        for cMeasureValue in setResponses:\n",
    "            values = str(row[columnResponse]).split(';')\n",
    "            values = [x.strip() for x in values ]\n",
    "            if(cMeasureValue in values):\n",
    "                if currT not in F:\n",
    "                    F[currT] = dict()\n",
    "                    F[currT][\"columnTot\"] = dict()\n",
    "                if cMeasureValue not in F[currT]:\n",
    "                    F[currT][cMeasureValue] = dict()\n",
    "                if nextT not in F[currT][cMeasureValue]:\n",
    "                    if nextT != np.nan:\n",
    "                        F[currT][cMeasureValue][nextT] = 0\n",
    "                F[currT][cMeasureValue][nextT] += 1      \n",
    "        if nextT not in F[currT][\"columnTot\"]:\n",
    "            F[currT][\"columnTot\"][nextT] = 0\n",
    "        F[currT][\"columnTot\"][nextT] += 1\n",
    "        \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
